{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules here\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments: True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(number: int, data_type: str, part: str, X_only = False):\n",
    "    \"\"\"\n",
    "    Loads image and label data based on the provided number, type, and part.\n",
    "    Parameters:\n",
    "        number (int): A number from 1 to 10, specifying the dataset part.\n",
    "        data_type (str): A string, either 'eval' or 'train', specifying the dataset type.\n",
    "        part (str): A string, either 'one' or 'two', specifying the dataset part.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two arrays, images and labels if available, otherwise only images.\n",
    "    Raises:\n",
    "        ValueError: If `number` is not between 1 and 10, `data_type` is not 'eval' or 'train',\n",
    "                    or `part` is not 'one' or 'two'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if inputs are valid\n",
    "    if number not in range(1, 11):\n",
    "        raise ValueError(\"Number must be between 1 and 10.\")\n",
    "    if data_type not in [\"eval\", \"train\"]:\n",
    "        raise ValueError(\"Type must be 'eval' or 'train'.\")\n",
    "    if part not in [\"one\", \"two\"]:\n",
    "        raise ValueError(\"Part must be 'one' or 'two'.\")\n",
    "\n",
    "    # Construct the path\n",
    "    path = f'dataset/part_{part}_dataset/{data_type}_data/{number}_{data_type}_data.tar.pth'\n",
    "    \n",
    "    # Load data\n",
    "    data = torch.load(path)\n",
    "    images = data.get('data')  # Expected shape (2500, 32, 32, 3)\n",
    "    \n",
    "    if X_only == True:\n",
    "        return images\n",
    "\n",
    "    if 'targets' in data:\n",
    "        labels = data['targets']  # Expected shape (2500,)\n",
    "        return images, labels\n",
    "    else:\n",
    "        return images  # Return only images if labels are not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data(1, \"train\", \"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique labels\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(images, labels, num_images=30):\n",
    "    \"\"\"\n",
    "    Visualizes the first `num_images` images and their corresponding labels in a grid.\n",
    "    Parameters:\n",
    "        images : ndarray, labels : ndarray.\n",
    "        num_images (int): Number of images to display (default is 30).\n",
    "    \"\"\"\n",
    "    # Set up the grid for displaying images\n",
    "    num_images = min(num_images, len(images))\n",
    "    cols = 6\n",
    "    rows = (num_images + cols - 1) // cols \n",
    "    \n",
    "    plt.figure(figsize=(10, rows * 2))  # Adjust figure size based on number of rows\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i], cmap= 'gray')\n",
    "        plt.title(f\"Label: {labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(images, labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_grayscale(images):\n",
    "#     \"\"\"\n",
    "#     Converts a batch of RGB images to grayscale.\n",
    "#     Parameters: images -> (N, 32, 32, 3) Returns: ndarray -> (N, 32, 32)\n",
    "#     \"\"\"\n",
    "#     N = len(images)\n",
    "#     grayscale_images = np.zeros((N, 32, 32), dtype = np.uint8)\n",
    "\n",
    "#     for k in range(N):\n",
    "#         for i in range(len(images[k])):\n",
    "#             for j in range(len(images[k][0])):\n",
    "#                 grayscale_images[k][i][j] = 0.3 * images[k][i][j][0] + 0.59 * images[k][i][j][1] + 0.11 * images[k][i][j][2]\n",
    "    \n",
    "#     return grayscale_images\n",
    "\n",
    "# Above code is also covert_to_grayscale but it's execution time is slow\n",
    "\n",
    "def convert_to_grayscale(images):\n",
    "    N = images.shape[0] \n",
    "    grayscale_images = np.zeros((N, 32, 32), dtype=np.uint8) \n",
    "\n",
    "    grayscale_images = (0.2989 * images[:, :, :, 0] + \n",
    "                        0.5870 * images[:, :, :, 1] + \n",
    "                        0.1140 * images[:, :, :, 2]).astype(np.uint8)\n",
    "\n",
    "    return grayscale_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = convert_to_grayscale(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(images, labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Flatten each 32x32 image to a 1024-dimensional vector\n",
    "N = images.shape[0]\n",
    "flattened_images = images.reshape(N, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LwP model with Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LwP_euclidean:\n",
    "    def __init__(self, n_prototypes):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            n_prototypes (int): Number of distinct labels.\n",
    "        \"\"\"\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.prototypes = None\n",
    "        self.labels = None\n",
    "        self.class_counts = None  # Track the count of samples per class\n",
    "        self.label_to_index = {}  # Maps each label to an index in the prototypes array\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains the model by finding prototypes based on the training data.\n",
    "        Parameters:\n",
    "            X (ndarray) -> (N, 1024)\n",
    "            y (ndarray): Labels -> (N,)\n",
    "        \"\"\"\n",
    "        unique_labels = np.unique(y)\n",
    "        self.labels = unique_labels\n",
    "        self.prototypes = np.zeros((self.n_prototypes, X.shape[1]))  # Placeholder for prototypes\n",
    "        self.class_counts = np.zeros(self.n_prototypes, dtype=int)\n",
    "\n",
    "        # Create label-to-index mapping\n",
    "        self.label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "        # Calculate prototypes for each label\n",
    "        for label in unique_labels:\n",
    "            class_samples = X[y == label]\n",
    "            if len(class_samples) > 0:\n",
    "                idx = self.label_to_index[label]\n",
    "                self.prototypes[idx] = np.mean(class_samples, axis=0)\n",
    "                self.class_counts[idx] = len(class_samples)\n",
    "\n",
    "    def euclidean_distance(self, a, b):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            a (ndarray): First vector.\n",
    "            b (ndarray): Second vector.\n",
    "        Returns:\n",
    "            float: Euclidean distance between a and b.\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "    def update(self, X_new, y_new):\n",
    "        \"\"\"\n",
    "        Updates the model with new training examples.\n",
    "        Parameters:\n",
    "            X_new (ndarray): New samples -> (M, 1024)\n",
    "            y_new (ndarray): New labels -> (M,)\n",
    "        \"\"\"\n",
    "        for label in np.unique(y_new):\n",
    "            new_samples = X_new[y_new == label]\n",
    "            n_new = len(new_samples)\n",
    "            if n_new > 0:\n",
    "                idx = self.label_to_index.get(label)\n",
    "                if idx is None:\n",
    "                    raise ValueError(f\"Label {label} not found in the model. Ensure that all labels are initialized in fit.\")\n",
    "\n",
    "                current_count = self.class_counts[idx]\n",
    "                total_count = current_count + n_new\n",
    "                new_mean = np.mean(new_samples, axis=0)\n",
    "                \n",
    "                # Update prototype as a weighted mean\n",
    "                self.prototypes[idx] = (current_count * self.prototypes[idx] + n_new * new_mean) / total_count\n",
    "                self.class_counts[idx] = total_count\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros(n_samples)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            distances = np.zeros(len(self.labels))\n",
    "            for j, prototype in enumerate(self.prototypes):\n",
    "                distances[j] = self.euclidean_distance(X[i], prototype)\n",
    "            predictions[i] = self.labels[np.argmin(distances)]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LwP model with euclidean distance on flattened_images\n",
    "model = LwP_euclidean(n_prototypes=10)\n",
    "model.fit(flattened_images, labels)\n",
    "\n",
    "# loading eval dataset\n",
    "X_eval, y_eval = load_data(1, \"eval\", \"one\")\n",
    "X_eval = convert_to_grayscale(X_eval)\n",
    "X_eval = X_eval.reshape(X_eval.shape[0], -1)\n",
    "\n",
    "# predicting on it\n",
    "predictions = model.predict(X_eval)\n",
    "accuracy = np.mean(predictions == np.asarray(y_eval))\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LwP model with Mahanolobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LwP_Mahalanobis:\n",
    "    def __init__(self, n_prototypes):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            n_prototypes (int): Number of distinct labels.\n",
    "        \"\"\"\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.prototypes = None\n",
    "        self.labels = None\n",
    "        self.inv_cov_matrix = None\n",
    "        self.class_counts = None  # Track the count of samples per class\n",
    "        self.label_to_index = {}  # Maps each label to an index in the prototypes array\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains the model by finding prototypes based on the training data.\n",
    "        Parameters:\n",
    "            X (ndarray) -> (N, 1024)\n",
    "            y (ndarray): Labels -> (N,)\n",
    "        \"\"\"\n",
    "        unique_labels = np.unique(y)\n",
    "        self.labels = unique_labels\n",
    "        self.prototypes = np.zeros((self.n_prototypes, X.shape[1]))  # Placeholder for prototypes\n",
    "        self.class_counts = np.zeros(self.n_prototypes, dtype=int)\n",
    "\n",
    "        # Create label-to-index mapping\n",
    "        self.label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "        # Calculate prototypes for each label\n",
    "        for label in unique_labels:\n",
    "            class_samples = X[y == label]\n",
    "            if len(class_samples) > 0:\n",
    "                idx = self.label_to_index[label]\n",
    "                self.prototypes[idx] = np.mean(class_samples, axis=0)\n",
    "                self.class_counts[idx] = len(class_samples)\n",
    "\n",
    "        # Compute the covariance matrix of the dataset and its inverse\n",
    "        covariance_matrix = np.cov(X, rowvar=False)\n",
    "        self.inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "    def mahalanobis_distance(self, a, b):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            a (ndarray): First vector.\n",
    "            b (ndarray): Second vector.\n",
    "        Returns:\n",
    "            float: Mahalanobis distance between a and b.\n",
    "        \"\"\"\n",
    "        diff = a - b\n",
    "        return np.sqrt(np.dot(np.dot(diff, self.inv_cov_matrix), diff.T))\n",
    "\n",
    "    def update(self, X_new, y_new):\n",
    "        \"\"\"\n",
    "        Updates the model with new training examples.\n",
    "        Parameters:\n",
    "            X_new (ndarray): New samples -> (M, 1024)\n",
    "            y_new (ndarray): New labels -> (M,)\n",
    "        \"\"\"\n",
    "        for label in np.unique(y_new):\n",
    "            new_samples = X_new[y_new == label]\n",
    "            n_new = len(new_samples)\n",
    "            if n_new > 0:\n",
    "                idx = self.label_to_index.get(label)\n",
    "                if idx is None:\n",
    "                    raise ValueError(f\"Label {label} not found in the model. Ensure that all labels are initialized in fit.\")\n",
    "\n",
    "                current_count = self.class_counts[idx]\n",
    "                total_count = current_count + n_new\n",
    "                new_mean = np.mean(new_samples, axis=0)\n",
    "                \n",
    "                # Update prototype as a weighted mean\n",
    "                self.prototypes[idx] = (current_count * self.prototypes[idx] + n_new * new_mean) / total_count\n",
    "                self.class_counts[idx] = total_count\n",
    "\n",
    "        # Update covariance matrix based on the combined data\n",
    "        combined_X = np.vstack([self.prototypes, X_new])\n",
    "        covariance_matrix = np.cov(combined_X, rowvar=False)\n",
    "        self.inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros(n_samples)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            distances = np.zeros(len(self.labels))\n",
    "            for j, prototype in enumerate(self.prototypes):\n",
    "                distances[j] = self.mahalanobis_distance(X[i], prototype)\n",
    "            predictions[i] = self.labels[np.argmin(distances)]\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LwP model with mahalanobis distance on flattened_images\n",
    "model = LwP_Mahalanobis(n_prototypes=10)\n",
    "model.fit(flattened_images, labels)\n",
    "\n",
    "# loading eval dataset\n",
    "X_eval, y_eval = load_data(1, \"eval\", \"one\")\n",
    "X_eval = convert_to_grayscale(X_eval)\n",
    "X_eval = X_eval.reshape(X_eval.shape[0], -1)\n",
    "\n",
    "# predicting on it\n",
    "predictions = model.predict(X_eval)\n",
    "accuracy = np.mean(predictions == np.asarray(y_eval))\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying new Approach by extracting features using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    \"\"\"\n",
    "    Extract features from a batch of CIFAR-10 images using a pre-trained ResNet18 model.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): A 4D array of shape (N, 32, 32, 3), where N is the number of images.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 2D tensor of shape (N, 512) containing the extracted features.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = 5\n",
    "    # Step 1: Convert the input images to a tensor and apply transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),  # Convert to PIL Image\n",
    "        transforms.Resize(224),   # Resize to 224x224\n",
    "        transforms.ToTensor(),     # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "        # transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]), \n",
    "        transforms.RandomHorizontalFlip(0.1),\n",
    "    ])\n",
    "\n",
    "    # Transform each image and create a tensor\n",
    "    transformed_images = torch.stack([transform(images[i]) for i in range(images.shape[0])])\n",
    "\n",
    "    # Step 2: Load pre-trained ResNet18 model\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove the classification layer\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # print(device)\n",
    "    model.to(device)\n",
    "    transformed_images = transformed_images.to(device)\n",
    "\n",
    "    torch.cuda.set_per_process_memory_fraction(1.0)\n",
    "\n",
    "    # Step 3: Feature extraction\n",
    "    features_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, transformed_images.size(0), batch_size):\n",
    "            torch.cuda.empty_cache()\n",
    "            batch_images = transformed_images[i : i + batch_size]  # Get features\n",
    "            batch_features = model(batch_images)  # Flatten the output\n",
    "            features_list.append(batch_features.view(batch_features.size(0), -1))\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(1, \"train\", \"one\")\n",
    "X_train = [t.cpu().numpy() for t in extract_features(X_train)]\n",
    "X_train = np.vstack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_gpu(df):\n",
    "    res = [t.cpu().numpy() for t in df]\n",
    "    return np.vstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LwP(n_prototypes=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval, y_eval = load_data(1, \"eval\", \"one\")\n",
    "X_eval = get_from_gpu(extract_features(X_eval))\n",
    "y_pred = model.predict(X_eval)\n",
    "acc = np.mean(y_eval == y_pred)\n",
    "print(f'Accuracy on eval dataset is {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO\n",
    "Train on D1\n",
    "\n",
    "for i = 2 to 10\n",
    "    update train on Di\n",
    "        for j: i to 1\n",
    "            predict Dj with ith model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = []\n",
    "data_train = []\n",
    "for i in range(2, 11):\n",
    "    X_e, y_e = load_data(i, 'eval', 'one')\n",
    "    X_t = load_data(i, 'train', 'one')\n",
    "\n",
    "    X_e = get_from_gpu(extract_features(X_e))\n",
    "    data_eval.append( (X_e, y_e) )\n",
    "\n",
    "    X_t = get_from_gpu(extract_features(X_t))\n",
    "    data_train.append( X_t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_eval = np.array(data_eval)\n",
    "# data_train = np.array(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(j):\n",
    "    X_eval, y_eval = data_eval[j]\n",
    "\n",
    "    y_pred = model.predict(X_eval)\n",
    "    accuracy = np.mean(y_pred == y_eval)\n",
    "\n",
    "    return f'{accuracy * 100:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for i in range(2, 11):\n",
    "    X = data_train[i - 2]\n",
    "    res.append([])\n",
    "\n",
    "    y_label = model.predict(X)\n",
    "    model.update(X, y_label)\n",
    "\n",
    "    for j in range(i, 0, -1):\n",
    "        acc = predict(j - 2)\n",
    "        res[i - 2].append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe dropping accuracy. Need higher accuracy on initial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing model - found a sweet spot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sufy @ Nov 7 midnight - 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1 in res:\n",
    "    for l2 in l1:\n",
    "        print(l2, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what I want to do here is on every new input dataset, learn the model which gives best accuracy on validation\n",
    "\n",
    "what this runs into - computational issues. There are $10^{2500}$ possible models straight out of the bat. Even if I take it down to say, choose among the top 2 by the current model, it is still $2^{2500}$ (between about $10^{750}$ and $10^{833}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do a naive run first\n",
    "res = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    X_e, y_e = load_data(i, 'eval', 'two')\n",
    "    X_t = load_data(i, 'train', 'two')\n",
    "\n",
    "    X_e = get_from_gpu(extract_features(X_e))\n",
    "    data_eval.append( (X_e, y_e) )\n",
    "\n",
    "    X_t = get_from_gpu(extract_features(X_t))\n",
    "    data_train.append( X_t )\n",
    "\n",
    "for i in range(11, 21):\n",
    "    X = data_train[i - 2]\n",
    "    res.append([])\n",
    "\n",
    "    y_label = model.predict(X)\n",
    "    model.update(X, y_label)\n",
    "\n",
    "    for j in range(i, 0, -1):\n",
    "        acc = predict(j - 2)\n",
    "        res[-1].append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1 in res:\n",
    "    for l2 in l1:\n",
    "        print(l2, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive is subpar. need better update for these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extracted_feature():\n",
    "     part = [\"one\", \"two\"]\n",
    "     types = [\"eval\", \"train\"]\n",
    "     numbers = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "     for p in part :\n",
    "          for t in types:\n",
    "               for n in numbers :\n",
    "                    images = load_data(n, t, p, True)\n",
    "                    images = extract_features(images)\n",
    "                    images_tensor = torch.from_numpy(images)\n",
    "\n",
    "                    save_path = f'extracted_feature/part_{part}_feature/{data_type}_feature/{number}_{data_type}_feature.tar.pth'\n",
    "\n",
    "                    torch.save(images_tensor, save_path)\n",
    "\n",
    "save_extracted_feature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mann nahi kar raha - amir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
