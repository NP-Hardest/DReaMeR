{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules here\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(number: int, data_type: str, part: str):\n",
    "    \"\"\"\n",
    "    Loads image and label data based on the provided number, type, and part.\n",
    "    Parameters:\n",
    "        number (int): A number from 1 to 10, specifying the dataset part.\n",
    "        data_type (str): A string, either 'eval' or 'train', specifying the dataset type.\n",
    "        part (str): A string, either 'one' or 'two', specifying the dataset part.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two arrays, images and labels if available, otherwise only images.\n",
    "    Raises:\n",
    "        ValueError: If `number` is not between 1 and 10, `data_type` is not 'eval' or 'train',\n",
    "                    or `part` is not 'one' or 'two'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if inputs are valid\n",
    "    if number not in range(1, 11):\n",
    "        raise ValueError(\"Number must be between 1 and 10.\")\n",
    "    if data_type not in [\"eval\", \"train\"]:\n",
    "        raise ValueError(\"Type must be 'eval' or 'train'.\")\n",
    "    if part not in [\"one\", \"two\"]:\n",
    "        raise ValueError(\"Part must be 'one' or 'two'.\")\n",
    "\n",
    "    # Construct the path\n",
    "    path = f'dataset/part_{part}_dataset/{data_type}_data/{number}_{data_type}_data.tar.pth'\n",
    "    \n",
    "    # Load data\n",
    "    data = torch.load(path)\n",
    "    images = data.get('data')  # Expected shape (2500, 32, 32, 3)\n",
    "    \n",
    "    if 'targets' in data:\n",
    "        labels = data['targets']  # Expected shape (2500,)\n",
    "        return images, labels\n",
    "    else:\n",
    "        return images  # Return only images if labels are not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data(1, \"train\", \"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique labels\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(images, labels, num_images=30):\n",
    "    \"\"\"\n",
    "    Visualizes the first `num_images` images and their corresponding labels in a grid.\n",
    "    Parameters:\n",
    "        images : ndarray, labels : ndarray.\n",
    "        num_images (int): Number of images to display (default is 30).\n",
    "    \"\"\"\n",
    "    # Set up the grid for displaying images\n",
    "    num_images = min(num_images, len(images))\n",
    "    cols = 6\n",
    "    rows = (num_images + cols - 1) // cols \n",
    "    \n",
    "    plt.figure(figsize=(10, rows * 2))  # Adjust figure size based on number of rows\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i], cmap= 'gray')\n",
    "        plt.title(f\"Label: {labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_grayscale(images):\n",
    "#     \"\"\"\n",
    "#     Converts a batch of RGB images to grayscale.\n",
    "#     Parameters: images -> (N, 32, 32, 3) Returns: ndarray -> (N, 32, 32)\n",
    "#     \"\"\"\n",
    "#     N = len(images)\n",
    "#     grayscale_images = np.zeros((N, 32, 32), dtype = np.uint8)\n",
    "\n",
    "#     for k in range(N):\n",
    "#         for i in range(len(images[k])):\n",
    "#             for j in range(len(images[k][0])):\n",
    "#                 grayscale_images[k][i][j] = 0.3 * images[k][i][j][0] + 0.59 * images[k][i][j][1] + 0.11 * images[k][i][j][2]\n",
    "    \n",
    "#     return grayscale_images\n",
    "\n",
    "# Above code very slow ->\n",
    "\n",
    "def convert_to_grayscale(images):\n",
    "    N = images.shape[0] \n",
    "    grayscale_images = np.zeros((N, 32, 32), dtype=np.uint8) \n",
    "\n",
    "    grayscale_images = (0.2989 * images[:, :, :, 0] + \n",
    "                        0.5870 * images[:, :, :, 1] + \n",
    "                        0.1140 * images[:, :, :, 2]).astype(np.uint8)\n",
    "\n",
    "    return grayscale_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = convert_to_grayscale(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(images, labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Flatten each 32x32 image to a 1024-dimensional vector\n",
    "N = images.shape[0]\n",
    "flattened_images = images.reshape(N, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LwP:\n",
    "    def __init__(self, n_prototypes):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            n_prototypes (int): Number of distinct labels.\n",
    "        \"\"\"\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.prototypes = None\n",
    "        self.labels = None\n",
    "        self.inv_cov_matrix = None\n",
    "        self.class_counts = None  # Track the count of samples per class\n",
    "        self.label_to_index = {}  # Maps each label to an index in the prototypes array\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains the model by finding prototypes based on the training data.\n",
    "        Parameters:\n",
    "            X (ndarray) -> (N, 1024)\n",
    "            y (ndarray): Labels -> (N,)\n",
    "        \"\"\"\n",
    "        unique_labels = np.unique(y)\n",
    "        self.labels = unique_labels\n",
    "        self.prototypes = np.zeros((self.n_prototypes, X.shape[1]))  # Placeholder for prototypes\n",
    "        self.class_counts = np.zeros(self.n_prototypes, dtype=int)\n",
    "\n",
    "        # Create label-to-index mapping\n",
    "        self.label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "        # Calculate prototypes for each label\n",
    "        for label in unique_labels:\n",
    "            class_samples = X[y == label]\n",
    "            if len(class_samples) > 0:\n",
    "                idx = self.label_to_index[label]\n",
    "                self.prototypes[idx] = np.mean(class_samples, axis=0)\n",
    "                self.class_counts[idx] = len(class_samples)\n",
    "\n",
    "        # Compute the covariance matrix of the dataset and its inverse\n",
    "        covariance_matrix = np.cov(X, rowvar=False)\n",
    "        self.inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "    def mahalanobis_distance(self, a, b):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            a (ndarray): First vector.\n",
    "            b (ndarray): Second vector.\n",
    "        Returns:\n",
    "            float: Mahalanobis distance between a and b.\n",
    "        \"\"\"\n",
    "        diff = a - b\n",
    "        return np.sqrt(np.dot(np.dot(diff, self.inv_cov_matrix), diff.T))\n",
    "\n",
    "    def update(self, X_new, y_new):\n",
    "        \"\"\"\n",
    "        Updates the model with new training examples.\n",
    "        Parameters:\n",
    "            X_new (ndarray): New samples -> (M, 1024)\n",
    "            y_new (ndarray): New labels -> (M,)\n",
    "        \"\"\"\n",
    "        for label in np.unique(y_new):\n",
    "            new_samples = X_new[y_new == label]\n",
    "            n_new = len(new_samples)\n",
    "            if n_new > 0:\n",
    "                idx = self.label_to_index.get(label)\n",
    "                if idx is None:\n",
    "                    raise ValueError(f\"Label {label} not found in the model. Ensure that all labels are initialized in fit.\")\n",
    "\n",
    "                current_count = self.class_counts[idx]\n",
    "                total_count = current_count + n_new\n",
    "                new_mean = np.mean(new_samples, axis=0)\n",
    "                \n",
    "                # Update prototype as a weighted mean\n",
    "                self.prototypes[idx] = (current_count * self.prototypes[idx] + n_new * new_mean) / total_count\n",
    "                self.class_counts[idx] = total_count\n",
    "\n",
    "        # Update covariance matrix based on the combined data\n",
    "        combined_X = np.vstack([self.prototypes, X_new])\n",
    "        covariance_matrix = np.cov(combined_X, rowvar=False)\n",
    "        self.inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros(n_samples)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            distances = np.zeros(len(self.labels))\n",
    "            for j, prototype in enumerate(self.prototypes):\n",
    "                distances[j] = self.mahalanobis_distance(X[i], prototype)\n",
    "            predictions[i] = self.labels[np.argmin(distances)]\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LwP(n_prototypes=10)\n",
    "model.fit(flattened_images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading eval dataset\n",
    "X_eval, y_eval = load_data(1, \"eval\", \"one\")\n",
    "X_eval = convert_to_grayscale(X_eval)\n",
    "X_eval = X_eval.reshape(X_eval.shape[0], -1)\n",
    "y_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_eval)\n",
    "accuracy = np.mean(predictions == np.asarray(y_eval))\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying new Approach by extracting features using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    \"\"\"\n",
    "    Extract features from a batch of CIFAR-10 images using a pre-trained ResNet18 model.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): A 4D array of shape (N, 32, 32, 3), where N is the number of images.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 2D tensor of shape (N, 512) containing the extracted features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert the input images to a tensor and apply transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),  # Convert to PIL Image\n",
    "        transforms.Resize(224),   # Resize to 224x224\n",
    "        transforms.ToTensor(),     # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    ])\n",
    "\n",
    "    # Transform each image and create a tensor\n",
    "    transformed_images = torch.stack([transform(images[i]) for i in range(images.shape[0])])\n",
    "\n",
    "    # Step 2: Load pre-trained ResNet18 model\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove the classification layer\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    transformed_images = transformed_images.to(device)\n",
    "\n",
    "    # Step 3: Feature extraction\n",
    "    with torch.no_grad():\n",
    "        features = model(transformed_images)  # Get features\n",
    "        features = features.view(features.size(0), -1)  # Flatten the output\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(1, \"train\", \"one\")\n",
    "X_train = extract_features(X_train)     \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LwP(n_prototypes=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval, y_eval = load_data(1, \"eval\", \"one\")\n",
    "X_eval = extract_features(X_eval)\n",
    "predictions = model.predict(X_eval)\n",
    "accuracy = np.mean(predictions == np.asarray(y_eval))\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = extract_features(load_data(2, \"train\", \"one\"))   \n",
    "y_label2 = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update(X_train2, y_label2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
